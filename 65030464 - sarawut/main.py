import cv2
import numpy as np
import os
import torch
from facenet_pytorch import MTCNN, InceptionResnetV1
import mediapipe as mp
import json
import requests
from datetime import datetime, timedelta, timezone
import time

# -------------------- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÅ‡∏•‡∏∞‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• --------------------
facenet_model = InceptionResnetV1(pretrained='vggface2').eval()
mtcnn = MTCNN(image_size=160, margin=60, min_face_size=20)
mp_face_mesh = mp.solutions.face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True)

face_database_path = "face_database.npy"
if os.path.exists(face_database_path):
    data = np.load(face_database_path, allow_pickle=True).item()
    if isinstance(data, dict):
        face_embeddings = data
    else:
        print("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô face_database.npy ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà dictionary!")
        exit()
else:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå face_database.npy!")
    exit()

# -------------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô --------------------
def recognize_face_with_mtcnn(face_resized):
    try:
        if face_resized is None or face_resized.size == 0:
            return None
        face_resized = cv2.resize(face_resized, (160, 160))
        face_rgb = cv2.cvtColor(face_resized, cv2.COLOR_BGR2RGB)
        face_tensor = torch.tensor(face_rgb, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0) / 255.0
        with torch.no_grad():
            embedding = facenet_model(face_tensor)
        return embedding.squeeze().numpy()
    except Exception as e:
        print("‚ö†Ô∏è Error in face embedding:", e)
        return None

def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

# -------------------- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ --------------------
server_url = "https://d076-49-237-33-240.ngrok-free.app/api/student-checks"
output_folder = "recorded_videos"
detected_folder = "detected_faces"
os.makedirs(output_folder, exist_ok=True)
os.makedirs(detected_folder, exist_ok=True)

clip_duration = 2 * 60  # 2 ‡∏ô‡∏≤‡∏ó‡∏µ
fps = 15
THAI_TIMEZONE = timezone(timedelta(hours=7))

# -------------------- ‡∏Å‡∏•‡πâ‡∏≠‡∏á RTSP --------------------
camera_ip = 'rtsp://Face495:cpe495@172.20.10.3:554/stream1'
capture = cv2.VideoCapture(camera_ip, cv2.CAP_FFMPEG)

if not capture.isOpened():
    print("Error: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á RTSP ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ FFmpeg")
    capture = cv2.VideoCapture(camera_ip, cv2.CAP_GSTREAMER)
    if not capture.isOpened():
        print("Error: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á RTSP ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ GStreamer")
        exit()
print("‚úÖ ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á RTSP ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")

capture.set(3, 1280)
capture.set(4, 720)
capture.set(cv2.CAP_PROP_BUFFERSIZE, 3)

fourcc = cv2.VideoWriter_fourcc(*'mp4v')

# -------------------- Loop ‡∏´‡∏•‡∏±‡∏Å --------------------
while True:
    # 1. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    video_filename = os.path.join(output_folder, f"record_{timestamp}.mp4")
    done_filename = video_filename + ".done"
    video_out = cv2.VideoWriter(video_filename, fourcc, fps, (1280, 720))

    print(f"üìπ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠: {video_filename}")
    start_time = time.time()

    while time.time() - start_time < clip_duration:
        ret, frame = capture.read()
        if not ret:
            print("‚ùå Error: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á!")
            break
        video_out.write(frame)
        cv2.imshow('Recording (Face Detection)', frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            capture.release()
            cv2.destroyAllWindows()
            exit()

    video_out.release()
    with open(done_filename, "w") as f:
        f.write("done")
    print(f"‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô: {video_filename}")

    # 2. ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
    print(f"üìÇ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠: {video_filename}")
    cap = cv2.VideoCapture(video_filename)
    if not cap.isOpened():
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏î‡πâ!")
        continue

    frame_index = 0
    frame_count = 0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    saved_faces = set()

    while frame_index < total_frames:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_index)
        ret, frame = cap.read()
        if not ret:
            break

        boxes, _ = mtcnn.detect(frame)
        if boxes is not None:
            for i, box in enumerate(boxes):
                x1, y1, x2, y2 = map(int, box)
                face = frame[y1:y2, x1:x2]

                if face.size == 0:
                    continue

                if (x1, y1, x2, y2) not in saved_faces:
                    face_filename = os.path.join(detected_folder, f"face_{frame_count:04d}.jpg")
                    cv2.imwrite(face_filename, face)
                    saved_faces.add((x1, y1, x2, y2))
                    frame_count += 1

        frame_index += 10

    cap.release()
    cv2.destroyAllWindows()
    print("‚úÖ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

    # 3. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤
    print("üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
    existing_names = set()

    for face_file in os.listdir(detected_folder):
        face_path = os.path.join(detected_folder, face_file)
        face_img = cv2.imread(face_path)
        face_embedding = recognize_face_with_mtcnn(face_img)

        if face_embedding is not None:
            name = "Unknown"
            best_similarity = float("-inf")

            for db_name, db_embedding in face_embeddings.items():
                similarity = cosine_similarity(face_embedding, db_embedding)
                print(f"üîç ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö {face_file} ‡∏Å‡∏±‡∏ö {db_name} | ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢: {similarity:.2f}")
                if similarity > best_similarity:
                    best_similarity = similarity
                    name = db_name

            if best_similarity >= 0.75 and name not in existing_names:
                print(f"üìå ‡πÉ‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÉ‡∏ô {face_file} ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö {name} (‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ {best_similarity:.2f})")
                now_th = datetime.now(THAI_TIMEZONE)

                attendance_data = {
                    "Student_ID": int(name),
                    "Course_ID": "CPE451",
                    "Check_Date": now_th.astimezone(timezone.utc).isoformat(timespec='milliseconds').replace('+00:00', 'Z'),
                    "Check_Time": now_th.strftime("%H:%M:%S")
                }

                try:
                    headers = {"Content-Type": "application/json"}
                    response = requests.post(server_url, json=attendance_data, headers=headers)
                    if response.status_code == 200:
                        print(f"‚úÖ ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {name}")
                    else:
                        print(f"‚ùå ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {name} | Status Code: {response.status_code} | Response: {response.text}")
                except Exception as e:
                    print(f"‚ö†Ô∏è Error sending data: {e}")

                existing_names.add(name)

        os.remove(face_path)
        print(f"‚ùå ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå: {face_file}")

    os.remove(done_filename)
    print(f"‚úÖ ‡∏•‡∏ö‡πÑ‡∏ü‡∏•‡πå .done ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {video_filename}")
    print("üîÑ ‡∏£‡∏≠‡∏Ñ‡∏•‡∏¥‡∏õ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ...")

